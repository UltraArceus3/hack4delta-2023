{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# from PIL import Image\n",
    "\n",
    "# checkpoint = \"EdBianchi/vit-fire-detection\"\n",
    "# detector = pipeline(model=checkpoint, task=\"image-classification\")\n",
    "# img = (\"optics.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
    "\n",
    "checkpoint = \"google/owlvit-base-patch32\"\n",
    "model = AutoModelForZeroShotObjectDetection.from_pretrained(checkpoint)\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Image.open('target.png')\n",
    "# target = Image.open('target2.png')\n",
    "query = Image.open('query.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array(target)\n",
    "target = np.zeros((x.shape[0], x.shape[1], 3), dtype=np.uint8)\n",
    "for i in range(x.shape[0]):\n",
    "    for j in range(x.shape[1]):\n",
    "        for k in range(x.shape[2]):\n",
    "            if k != 3:\n",
    "                target[i, j, k] = x[i, j, k]\n",
    "\n",
    "x = np.array(query)\n",
    "query = np.zeros((x.shape[0], x.shape[1], 3), dtype=np.uint8)\n",
    "for i in range(x.shape[0]):\n",
    "    for j in range(x.shape[1]):\n",
    "        for k in range(x.shape[2]):\n",
    "            if k != 3:\n",
    "                query[i, j, k] = x[i, j, k]\n",
    "\n",
    "target = Image.fromarray(target)\n",
    "query = Image.fromarray(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=target, query_images=query, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from PIL import ImageDraw\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.image_guided_detection(**inputs)\n",
    "    target_sizes = torch.tensor([target.size[::-1]])\n",
    "    results = processor.post_process_image_guided_detection(outputs=outputs, target_sizes=target_sizes)[0]\n",
    "\n",
    "draw = ImageDraw.Draw(target)\n",
    "\n",
    "scores = results[\"scores\"].tolist()\n",
    "boxes = results[\"boxes\"].tolist()\n",
    "\n",
    "for box, score in zip(boxes, scores):\n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    draw.rectangle((xmin, ymin, xmax, ymax), outline=\"white\", width=4)\n",
    "\n",
    "target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
